import pandas as pd
import requests
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# Configuration des chemins relatifs √† la racine du projet
# Path(__file__).parent renvoie le dossier 'src'
# .parent remonte au dossier racine 'electricite-prediction-europe'
PROJECT_ROOT = Path(__file__).parent.parent
DATA_DIR = PROJECT_ROOT / "data"
RAW_DATA_DIR = DATA_DIR / "raw"
PROCESSED_DATA_DIR = DATA_DIR / "processed"

# URL de base pour les donn√©es OPSD
OPSD_BASE_URL = "https://data.open-power-system-data.org/time_series/2020-10-06"

# Fichiers disponibles au t√©l√©chargement
DATA_FILES = {
    "hourly": "time_series_60min_singleindex.csv",
    "15min": "time_series_15min_singleindex.csv",
    "30min": "time_series_30min_singleindex.csv"
}


def ensure_directories():
    
    RAW_DATA_DIR.mkdir(parents=True, exist_ok=True)
    PROCESSED_DATA_DIR.mkdir(parents=True, exist_ok=True)
    
    # Cr√©ation du dossier external
    external_dir = DATA_DIR / "external"
    external_dir.mkdir(parents=True, exist_ok=True)
    
    return {
        'raw': RAW_DATA_DIR,
        'processed': PROCESSED_DATA_DIR,
        'external': external_dir
    }


def download_opsd_data(file_type="hourly", force_download=False, verbose=True):
   
    # S'assurer que les dossiers existent
    ensure_directories()
    
    # Validation du param√®tre file_type
    if file_type not in DATA_FILES:
        raise ValueError(f"file_type doit √™tre parmi {list(DATA_FILES.keys())}")
    
    filename = DATA_FILES[file_type]
    local_path = RAW_DATA_DIR / filename
    
    # V√©rification de l'existence du fichier
    if local_path.exists() and not force_download:
        if verbose:
            file_size_mb = local_path.stat().st_size / (1024**2)
            print(f"‚úì Fichier {filename} d√©j√† pr√©sent ({file_size_mb:.2f} MB)")
            print(f"  Emplacement : {local_path}")
        return local_path
    
    # Construction de l'URL compl√®te
    url = f"{OPSD_BASE_URL}/{filename}"
    
    if verbose:
        print(f"üì• T√©l√©chargement de {filename}...")
        print(f"   Source : {url}")
        print("   (Cela peut prendre quelques minutes)")
    
    try:
        # Requ√™te HTTP avec streaming pour g√©rer les gros fichiers
        response = requests.get(url, stream=True, timeout=120)
        response.raise_for_status()
        
        # R√©cup√©ration de la taille totale si disponible
        total_size = int(response.headers.get('content-length', 0))
        
        # T√©l√©chargement par chunks pour √©viter de saturer la m√©moire
        with open(local_path, 'wb') as f:
            downloaded = 0
            chunk_size = 8192  # 8 KB par chunk
            
            for chunk in response.iter_content(chunk_size=chunk_size):
                if chunk:
                    f.write(chunk)
                    downloaded += len(chunk)
                    
                    # Affichage p√©riodique de la progression
                    if verbose and downloaded % (10 * 1024 * 1024) == 0:
                        if total_size > 0:
                            progress = (downloaded / total_size) * 100
                            print(f"   {downloaded/(1024**2):.1f} MB / "
                                  f"{total_size/(1024**2):.1f} MB ({progress:.1f}%)")
                        else:
                            print(f"   {downloaded/(1024**2):.1f} MB t√©l√©charg√©s")
        
        if verbose:
            file_size_mb = local_path.stat().st_size / (1024**2)
            print(f"‚úì T√©l√©chargement termin√© : {file_size_mb:.2f} MB")
            print(f"  Sauvegard√© dans : {local_path}")
        
        return local_path
        
    except requests.exceptions.RequestException as e:
        if verbose:
            print(f"‚ùå Erreur lors du t√©l√©chargement : {e}")
            print("\nüí° Solutions possibles :")
            print("   1. V√©rifiez votre connexion internet")
            print("   2. T√©l√©chargez manuellement depuis :")
            print("      https://data.open-power-system-data.org/time_series/")
            print(f"   3. Placez le fichier dans : {RAW_DATA_DIR}")
        return None


def load_opsd_data(file_type="hourly", nrows=None, verbose=True):
    """
    Charge les donn√©es OPSD dans un DataFrame Pandas.
    """
    # T√©l√©chargement ou v√©rification du fichier
    file_path = download_opsd_data(file_type=file_type, verbose=verbose)
    
    if file_path is None:
        raise FileNotFoundError(
            f"Impossible de charger les donn√©es. "
            f"Le fichier {DATA_FILES[file_type]} n'a pas pu √™tre t√©l√©charg√©."
        )
    
    if verbose:
        print(f"\nüìä Chargement des donn√©es depuis {file_path.name}...")
        if nrows:
            print(f"   Mode test : {nrows:,} lignes seulement")
    
    try:
        # Lecture optimis√©e du CSV avec Pandas
        # parse_dates : conversion automatique des dates
        # index_col : utilisation de la colonne temporelle comme index
        # low_memory : False pour une meilleure d√©tection des types
        df = pd.read_csv(
            file_path,
            parse_dates=['utc_timestamp'],
            index_col='utc_timestamp',
            low_memory=False,
            nrows=nrows
        )
        
        if verbose:
            print(f"‚úì Donn√©es charg√©es avec succ√®s")
            print(f"  Dimensions : {df.shape[0]:,} lignes √ó {df.shape[1]:,} colonnes")
            print(f"  P√©riode : {df.index.min().date()} √† {df.index.max().date()}")
            print(f"  M√©moire : {df.memory_usage(deep=True).sum() / (1024**2):.2f} MB")
        
        return df
        
    except Exception as e:
        print(f"‚ùå Erreur lors du chargement : {e}")
        raise


def get_available_countries(df, verbose=True):
    """
    Identifie tous les pays disponibles dans le dataset.
    """
    # Extraction des codes pays depuis les noms de colonnes
    # Les colonnes suivent le format : PAYS_type_de_donn√©e
    countries = set()
    
    for col in df.columns:
        # S√©paration par underscore
        parts = col.split('_')
        if len(parts) > 0:
            # Le code pays est g√©n√©ralement le premier √©l√©ment
            country_code = parts[0]
            # Filtrage des codes valides (2-3 lettres majuscules)
            if country_code.isupper() and 2 <= len(country_code) <= 3:
                countries.add(country_code)
    
    countries = sorted(list(countries))
    
    if verbose:
        print(f"\nüåç Pays disponibles dans le dataset : {len(countries)}")
        # Affichage en colonnes pour meilleure lisibilit√©
        for i in range(0, len(countries), 10):
            print(f"   {', '.join(countries[i:i+10])}")
    
    return countries


def get_price_columns(df, verbose=True):
    """
    Identifie toutes les colonnes contenant des prix day-ahead.
    """
    # Filtrage des colonnes de prix
    price_cols = [col for col in df.columns if 'price_day_ahead' in col.lower()]
    
    if len(price_cols) == 0:
        if verbose:
            print("‚ö†Ô∏è  Aucune colonne de prix day-ahead trouv√©e")
        return pd.DataFrame()
    
    # Analyse de chaque colonne de prix
    price_info = []
    for col in price_cols:
        non_null = df[col].notna().sum()
        total = len(df)
        completeness = (non_null / total) * 100
        
        # Extraction de la zone depuis le nom de colonne
        zone = col.replace('_price_day_ahead', '')
        
        # Calcul des dates de d√©but et fin des donn√©es disponibles
        valid_data = df[df[col].notna()]
        if len(valid_data) > 0:
            first_date = valid_data.index.min()
            last_date = valid_data.index.max()
        else:
            first_date = None
            last_date = None
        
        price_info.append({
            'Zone': zone,
            'Column_name': col,
            'Non_null_values': non_null,
            'Total_values': total,
            'Completeness_%': completeness,
            'First_date': first_date,
            'Last_date': last_date,
            'Coverage_days': (last_date - first_date).days if first_date else 0
        })
    
    # Cr√©ation du DataFrame r√©capitulatif
    price_df = pd.DataFrame(price_info)
    price_df = price_df.sort_values('Completeness_%', ascending=False)
    
    if verbose:
        print(f"\nüí∞ Analyse des prix day-ahead disponibles")
        print(f"   Nombre de zones avec prix : {len(price_cols)}")
        print(f"\n   Top 10 des zones les mieux couvertes :")
        print(price_df[['Zone', 'Completeness_%', 'Coverage_days']].head(10).to_string(index=False))
    
    return price_df


def save_processed_data(df, filename, verbose=True):
    """
    Sauvegarde un DataFrame trait√© dans le dossier processed.
    """
    # S'assurer que les dossiers existent
    ensure_directories()
    
    # Ajout de l'extension .csv si n√©cessaire
    if not filename.endswith('.csv'):
        filename = f"{filename}.csv"
    
    # Chemin complet
    filepath = PROCESSED_DATA_DIR / filename
    
    # Sauvegarde
    df.to_csv(filepath)
    
    if verbose:
        file_size_mb = filepath.stat().st_size / (1024**2)
        print(f"‚úì Donn√©es sauvegard√©es : {filepath}")
        print(f"  Dimensions : {df.shape[0]:,} √ó {df.shape[1]:,}")
        print(f"  Taille : {file_size_mb:.2f} MB")
    
    return filepath


def load_processed_data(filename, verbose=True):
    """
    Charge un DataFrame depuis le dossier processed.
    """
    # Ajout de l'extension .csv si n√©cessaire
    if not filename.endswith('.csv'):
        filename = f"{filename}.csv"
    
    filepath = PROCESSED_DATA_DIR / filename
    
    # V√©rification de l'existence
    if not filepath.exists():
        raise FileNotFoundError(
            f"Le fichier {filename} n'existe pas dans {PROCESSED_DATA_DIR}"
        )
    
    # Chargement avec parsing de l'index temporel si pr√©sent
    df = pd.read_csv(filepath, index_col=0, parse_dates=True)
    
    if verbose:
        print(f"‚úì Donn√©es charg√©es : {filepath.name}")
        print(f"  Dimensions : {df.shape[0]:,} √ó {df.shape[1]:,}")
        if isinstance(df.index, pd.DatetimeIndex):
            print(f"  P√©riode : {df.index.min().date()} √† {df.index.max().date()}")
    
    return df