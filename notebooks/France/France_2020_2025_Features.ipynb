{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering - Prix Électricité France (2020-2025)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. Chargement du Dataset Nettoyé"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset chargé: (52147, 30)\n",
            "Colonnes: ['biomass', 'gas', 'coal', 'oil', 'hydro_pumped', 'hydro_river', 'hydro_reservoir', 'nuclear', 'solar', 'waste', 'wind_onshore', 'price_day_ahead', 'temperature', 'cloud_cover', 'wind_speed', 'load', 'load_forecast', 'wind', 'hydro', 'price_raw', 'year', 'load_bin', 'nuclear_bin', 'month', 'day_name', 'hour', 'dayofweek', 'is_weekend', 'season_lbl', 'is_holiday']\n"
          ]
        }
      ],
      "source": [
        "# Charger le dataset nettoyé du notebook EDA\n",
        "df = pd.read_csv('../../data/processed/df_features_france_2020_2025.csv', \n",
        "                parse_dates=['utc_timestamp'],\n",
        "                index_col='utc_timestamp')\n",
        "print(f\"Dataset chargé: {df.shape}\")\n",
        "print(f\"Colonnes: {list(df.columns)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Features Temporelles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Création des features temporelles...\n",
            " features temporelles créées\n"
          ]
        }
      ],
      "source": [
        "print(\" Création des features temporelles...\")\n",
        "df_features = df.copy()\n",
        "\n",
        "df_features['hour'] = df_features.index.hour\n",
        "df_features['day_of_week'] = df_features.index.dayofweek\n",
        "df_features['day_of_year'] = df_features.index.dayofyear\n",
        "df_features['month'] = df_features.index.month\n",
        "df_features['year'] = df_features.index.year\n",
        "df_features['quarter'] = df_features.index.quarter\n",
        "df_features['is_weekend'] = (df_features['day_of_week'] >= 5).astype(int)\n",
        "\n",
        "season_map = {12: 'Winter', 1: 'Winter', 2: 'Winter',\n",
        "              3: 'Spring', 4: 'Spring', 5: 'Spring',\n",
        "              6: 'Summer', 7: 'Summer', 8: 'Summer',\n",
        "              9: 'Fall', 10: 'Fall', 11: 'Fall'}\n",
        "df_features['season'] = df_features['month'].map(season_map)\n",
        "\n",
        "french_holidays = [(1,1), (5,1), (5,8), (7,14), (8,15), (11,1), (11,11), (12,25)]\n",
        "df_features['is_holiday'] = df_features.index.to_series().apply(\n",
        "    lambda x: 1 if (x.month, x.day) in french_holidays else 0\n",
        ")\n",
        "\n",
        "print(f\" features temporelles créées\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Lag Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Création des lag features...\n",
            "lag features créées\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n Création des lag features...\")\n",
        "target = 'price_day_ahead'\n",
        "\n",
        "# Lags prix\n",
        "for lag in [1, 3, 6, 12, 24, 168]:\n",
        "    df_features[f'price_lag_{lag}h'] = df_features[target].shift(lag)\n",
        "\n",
        "# Lags charge\n",
        "for lag in [1, 3, 6, 12, 24]:\n",
        "    df_features[f'load_lag_{lag}h'] = df_features['load'].shift(lag)\n",
        "\n",
        "print(f\"lag features créées\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Rolling Windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Création des rolling windows...\n",
            "  rolling window features créées\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n Création des rolling windows...\")\n",
        "\n",
        "for window in [6, 24, 168]:\n",
        "    df_features[f'price_rolling_mean_{window}h'] = df_features[target].shift(1).rolling(window=window).mean()\n",
        "    df_features[f'price_rolling_std_{window}h'] = df_features[target].shift(1).rolling(window=window).std()\n",
        "    df_features[f'price_rolling_min_{window}h'] = df_features[target].shift(1).rolling(window=window).min()\n",
        "    df_features[f'price_rolling_max_{window}h'] = df_features[target].shift(1).rolling(window=window).max()\n",
        "\n",
        "for window in [6, 24]:\n",
        "    df_features[f'load_rolling_mean_{window}h'] = df_features['load'].rolling(window=window).mean()\n",
        "    df_features[f'load_rolling_std_{window}h'] = df_features['load'].rolling(window=window).std()\n",
        "\n",
        "print(f\"  rolling window features créées\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Features Dérivées"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Création des features dérivées...\n",
            " features dérivées créées\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nCréation des features dérivées...\")\n",
        "\n",
        "if 'solar' in df_features.columns and 'wind' in df_features.columns:\n",
        "    df_features['renewable_generation'] = df_features['solar'] + df_features['wind']\n",
        "\n",
        "if 'renewable_generation' in df_features.columns and 'nuclear' in df_features.columns:\n",
        "    df_features['total_generation'] = df_features['renewable_generation'] + df_features['nuclear']\n",
        "\n",
        "if 'load' in df_features.columns and 'total_generation' in df_features.columns:\n",
        "    df_features['residual_load'] = df_features['load'] - df_features['total_generation']\n",
        "\n",
        "df_features['price_delta'] = df_features[target].diff()\n",
        "df_features['price_delta_pct'] = df_features[target].pct_change() * 100\n",
        "\n",
        "if 'renewable_generation' in df_features.columns and 'load' in df_features.columns:\n",
        "    df_features['renewable_ratio'] = df_features['renewable_generation'] / (df_features['load'] + 1)\n",
        "\n",
        "print(f\" features dérivées créées\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Features Interactives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Création des features interactives...\n",
            "  features interactives créées\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nCréation des features interactives...\")\n",
        "\n",
        "df_features['load_x_hour'] = df_features['load'] * df_features['hour'] / 100\n",
        "\n",
        "if 'temperature' in df_features.columns and 'cloud_cover' in df_features.columns:\n",
        "    df_features['temp_x_cloud'] = df_features['temperature'] * df_features['cloud_cover']\n",
        "\n",
        "if 'temperature' in df_features.columns and 'load' in df_features.columns:\n",
        "    df_features['temp_x_load'] = df_features['temperature'] * df_features['load'] / 1000\n",
        "\n",
        "if 'wind' in df_features.columns and 'wind_speed' in df_features.columns:\n",
        "    df_features['wind_x_speed'] = df_features['wind'] * df_features['wind_speed']\n",
        "\n",
        "print(f\"  features interactives créées\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Résumé et Nettoyage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Features totales: 71\n",
            "Observations avant nettoyage: 52147\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"Features totales: {df_features.shape[1]}\")\n",
        "print(f\"Observations avant nettoyage: {df_features.shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "404bd996",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Observations après nettoyage: 51810\n",
            "Lignes supprimées (NaN): 337\n"
          ]
        }
      ],
      "source": [
        "\n",
        "df_features = df_features.dropna()\n",
        "print(f\"Observations après nettoyage: {df_features.shape[0]}\")\n",
        "print(f\"Lignes supprimées (NaN): {df.shape[0] - df_features.shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5600d2f0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset ML prêt: (51810, 71)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "df_ml = df_features.copy()\n",
        "print(f\"\\nDataset ML prêt: {df_ml.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "314d5619",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Nouvelles features (41):\n",
            "   1. day_of_week\n",
            "   2. day_of_year\n",
            "   3. quarter\n",
            "   4. season\n",
            "   5. price_lag_1h\n",
            "   6. price_lag_3h\n",
            "   7. price_lag_6h\n",
            "   8. price_lag_12h\n",
            "   9. price_lag_24h\n",
            "  10. price_lag_168h\n",
            "  11. load_lag_1h\n",
            "  12. load_lag_3h\n",
            "  13. load_lag_6h\n",
            "  14. load_lag_12h\n",
            "  15. load_lag_24h\n",
            "  16. price_rolling_mean_6h\n",
            "  17. price_rolling_std_6h\n",
            "  18. price_rolling_min_6h\n",
            "  19. price_rolling_max_6h\n",
            "  20. price_rolling_mean_24h\n",
            "  21. price_rolling_std_24h\n",
            "  22. price_rolling_min_24h\n",
            "  23. price_rolling_max_24h\n",
            "  24. price_rolling_mean_168h\n",
            "  25. price_rolling_std_168h\n",
            "  26. price_rolling_min_168h\n",
            "  27. price_rolling_max_168h\n",
            "  28. load_rolling_mean_6h\n",
            "  29. load_rolling_std_6h\n",
            "  30. load_rolling_mean_24h\n",
            "  31. load_rolling_std_24h\n",
            "  32. renewable_generation\n",
            "  33. total_generation\n",
            "  34. residual_load\n",
            "  35. price_delta\n",
            "  36. price_delta_pct\n",
            "  37. renewable_ratio\n",
            "  38. load_x_hour\n",
            "  39. temp_x_cloud\n",
            "  40. temp_x_load\n",
            "  41. wind_x_speed\n"
          ]
        }
      ],
      "source": [
        "\n",
        "new_features = [c for c in df_features.columns if c not in df.columns]\n",
        "print(f\"\\nNouvelles features ({len(new_features)}):\")\n",
        "for i, feat in enumerate(new_features, 1):\n",
        "    print(f\"  {i:2d}. {feat}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sauvegarde"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Dataset sauvegardé: ../data/processed/df_ml_france_2020_2025.csv\n"
          ]
        }
      ],
      "source": [
        "# Sauvegarder pour le notebook de modélisation\n",
        "df_ml.to_csv('../../data/processed/df_ml_france_2020_2025.csv')\n",
        "print(\"\\n Dataset sauvegardé: ../data/processed/df_ml_france_2020_2025.csv\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
